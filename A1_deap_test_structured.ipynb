{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import Levenshtein"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Duration', 'Distance', 'Pickup_longitude', 'Pickup_latitude',\n",
       "       'Haversine', 'Pmonth', 'Pickup_day', 'Pickup_hour', 'Pickup_minute',\n",
       "       'Pickup_weekday', 'Dropoff_hour', 'Dropoff_minute', 'Temp', 'Precip',\n",
       "       'Wind', 'Humid', 'Solar', 'Snow', 'Dust'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset (cleaned)\n",
    "df = pd.read_csv(r'cleaned_data_simplified.csv', index_col=0)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Duration' 'Distance' 'Pickup_longitude' 'Pickup_latitude' 'Haversine'\n",
      " 'Pmonth' 'Pickup_day' 'Pickup_hour' 'Pickup_minute' 'Pickup_weekday'\n",
      " 'Dropoff_hour' 'Dropoff_minute' 'Temp' 'Precip' 'Wind' 'Humid' 'Solar'\n",
      " 'Snow' 'Dust']\n"
     ]
    }
   ],
   "source": [
    "# Printing the column headings to better understand the features\n",
    "print(train_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import gp, creator, base, tools, algorithms\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protected_div(x,y):\n",
    "    if y == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return x/y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pset = gp.PrimitiveSet(\"MAIN\", 18)\n",
    "pset.addPrimitive(operator.add, 2)\n",
    "pset.addPrimitive(operator.sub, 2)\n",
    "pset.addPrimitive(operator.mul, 2)\n",
    "# pset.addPrimitive(protected_div,2)\n",
    "# pset.addPrimitive(operator.pow, 2)\n",
    "\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMin, pset=pset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toolbox setup\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=2)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"compile\", gp.compile, pset=pset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper similarity function for strucutred implementation\n",
    "def calculate_similarity(tree1, tree2):\n",
    "    return Levenshtein.distance(tree1, tree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_local_minima : list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fitness(individual, dataset : pd.DataFrame):\n",
    "    # print(\"started evaluation of fitness\")\n",
    "    func = toolbox.compile(expr=individual)\n",
    "    dataset.reset_index()\n",
    "\n",
    "    raw_fitness = 0\n",
    "\n",
    "    sample = dataset.sample(n=10000, random_state=10)\n",
    "\n",
    "    for index, row in sample.iterrows():\n",
    "        durations = row.get(\"Duration\")\n",
    "        distances = row.get(\"Distance\")\n",
    "        pickup_longs = row.get(\"Pickup_longitude\")\n",
    "        pickup_lats = row.get(\"Pickup_latitude\")\n",
    "        haversines = row.get(\"Haversine\")\n",
    "        pmonths = row.get(\"Pmonth\")\n",
    "        pdays = row.get(\"Pickup_day\")\n",
    "        phours = row.get(\"Pickup_hour\")\n",
    "        pmins = row.get(\"Pickup_minute\")\n",
    "        pweekdays = row.get(\"Pickup_weekday\")\n",
    "        dhours = row.get(\"Dropoff_hour\")\n",
    "        dmins = row.get(\"Dropoff_minute\")\n",
    "        temps = row.get(\"Temp\")\n",
    "        precips = row.get(\"Precip\")\n",
    "        winds = row.get(\"Wind\")\n",
    "        humids = row.get(\"Humid\")\n",
    "        solars = row.get(\"Solar\")\n",
    "        snows = row.get(\"Snow\")\n",
    "        dusts = row.get(\"Dust\")\n",
    "\n",
    "        estimate = func(distances, pickup_longs, pickup_lats,\n",
    "                        haversines,\n",
    "                        pmonths, pdays, phours, pmins,\n",
    "                        pweekdays, dhours, dmins, \n",
    "                        temps, precips, winds,\n",
    "                        humids, solars, snows, dusts)\n",
    "        \n",
    "        actual = durations\n",
    "\n",
    "        raw_fitness = raw_fitness + abs(actual - estimate)\n",
    "    \n",
    "    average_fitness = raw_fitness / len(sample)\n",
    "    # print(\"averge fitness: \" + str(average_fitness))\n",
    "\n",
    "    total_distance = 0\n",
    "    average_distance = 0.9\n",
    "    if past_local_minima != None:\n",
    "        for past_solution in past_local_minima:\n",
    "            total_distance = total_distance + calculate_similarity(str(individual), str(past_solution))\n",
    "\n",
    "        average_distance = total_distance / len(sample)\n",
    "\n",
    "    # adjusted fitness is penalised by adding a number which increases with smaller distances\n",
    "    # essentially, we make the individual less fit if it's exploring already-explored minima\n",
    "    adjusted_fitness = average_fitness + ( 1 / 0.1 + average_distance)\n",
    "    # print(\"adjusted fitness: \" + str(adjusted_fitness))\n",
    "\n",
    "    # using average fitness to reward overall good even if it has one or two weird cases\n",
    "    return average_fitness,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_past_minima(minima : list):\n",
    "    best = None\n",
    "    best_fitness = None\n",
    "    for tree in minima:\n",
    "        # do some fancy thing that calculates its fitness\n",
    "        fitness = 0\n",
    "        if best_fitness == None or fitness > best_fitness:\n",
    "            best = tree\n",
    "            best_fitness = fitness\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register(\"evaluate\", eval_fitness, dataset=train_df)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=10)\n",
    "toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n",
    "toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
    "\n",
    "toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=25))\n",
    "toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats_size = tools.Statistics(len)\n",
    "mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)\n",
    "mstats.register(\"avg\", np.mean)\n",
    "mstats.register(\"std\", np.std)\n",
    "mstats.register(\"min\", np.min)\n",
    "mstats.register(\"max\", np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hof = tools.HallOfFame(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MINIMA LOOP COMPLETED: 0\n",
      "gen\tnevals\tavg    \tstd    \tmin    \tmax   \n",
      "0  \t150   \t13637.2\t62513.8\t15.1105\t395027\n",
      "1  \t105   \t2.40474e+06\t2.88013e+07\t13.2613\t3.53914e+08\n",
      "MINIMA LOOP COMPLETED: 1\n",
      "gen\tnevals\tavg    \tstd    \tmin    \tmax   \n",
      "0  \t150   \t10633.9\t42695.3\t15.1105\t360161\n",
      "1  \t108   \t12967  \t79567.2\t15.1105\t738835\n",
      "MINIMA LOOP COMPLETED: 2\n",
      "gen\tnevals\tavg    \tstd   \tmin    \tmax        \n",
      "0  \t150   \t19031.8\t143606\t14.5146\t1.69978e+06\n",
      "1  \t103   \t12635.4\t89133.5\t14.5146\t985445     \n",
      "MINIMA LOOP COMPLETED: 3\n",
      "gen\tnevals\tavg   \tstd    \tmin    \tmax   \n",
      "0  \t150   \t4083.7\t16882.6\t14.9838\t116777\n",
      "1  \t113   \t5762.44\t38463.3\t14.5146\t391172\n",
      "MINIMA LOOP COMPLETED: 4\n",
      "gen\tnevals\tavg    \tstd    \tmin    \tmax   \n",
      "0  \t150   \t4215.77\t33155.2\t14.4868\t395027\n",
      "1  \t108   \t59789.5\t636338 \t14.3256\t7.77077e+06\n",
      "MINIMA LOOP COMPLETED: 5\n",
      "gen\tnevals\tavg   \tstd        \tmin    \tmax        \n",
      "0  \t150   \t121280\t1.43181e+06\t15.1565\t1.75976e+07\n",
      "1  \t113   \t8155.28\t80850.6    \t14.9838\t984823     \n",
      "MINIMA LOOP COMPLETED: 6\n",
      "gen\tnevals\tavg    \tstd    \tmin    \tmax   \n",
      "0  \t150   \t6537.44\t38392.7\t15.1566\t391953\n",
      "1  \t107   \t1811.24\t8062.86\t14.4868\t54439.4\n",
      "MINIMA LOOP COMPLETED: 7\n",
      "gen\tnevals\tavg   \tstd        \tmin    \tmax       \n",
      "0  \t150   \t124716\t1.42514e+06\t15.1786\t1.7514e+07\n",
      "1  \t115   \t6001.69\t39363.6    \t13.2613\t395027    \n",
      "MINIMA LOOP COMPLETED: 8\n",
      "gen\tnevals\tavg    \tstd  \tmin    \tmax   \n",
      "0  \t150   \t8222.31\t76994\t14.7483\t940035\n",
      "1  \t106   \t6730.26\t43474.4\t14.2842\t395042\n",
      "MINIMA LOOP COMPLETED: 9\n",
      "gen\tnevals\tavg    \tstd  \tmin    \tmax   \n",
      "0  \t150   \t4815.72\t21029\t14.4072\t185340\n",
      "1  \t118   \t118286 \t1.42515e+06\t13.9641\t1.7514e+07\n"
     ]
    }
   ],
   "source": [
    "# now have to repeat process 'num_loops_per_minima' times to explore as much as possible\n",
    "num_loops_per_minima = 10\n",
    "for i in range (0,num_loops_per_minima):\n",
    "    pop = toolbox.population(n=150)\n",
    "    print(\"MINIMA LOOP COMPLETED: \" + str(i))\n",
    "    pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.4, mutpb=0.6, stats=stats_fit,\n",
    "                                       halloffame=hof, verbose=True, ngen=1)\n",
    "    past_local_minima.append(hof[0])\n",
    "\n",
    "# TODO - at present, first iteration faces advantage, because there is no penalty applied to it - you'll need to do one last check against the whole \"past_local_minima\" list to see which item there is actually the fittest individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul(ARG4, ARG3)\n"
     ]
    }
   ],
   "source": [
    "best_individual_after_comparison = compare_past_minima(past_local_minima)\n",
    "print(str(best_individual_after_comparison))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'add(add(ARG3, ARG3), add(add(add(add(add(ARG3, ARG3), add(ARG3, ARG15)), ARG13), ARG3), ARG3))'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(past_local_minima[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "checkpoint = dict(population=pop, generation=10, halloffame=hof,\n",
    "                      logbook=log, rndstate=10)\n",
    "\n",
    "with open(\"deap_report_model.pkl\", \"wb\") as cp_file:\n",
    "    pickle.dump(checkpoint, cp_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
